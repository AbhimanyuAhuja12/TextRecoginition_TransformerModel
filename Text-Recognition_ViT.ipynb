{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc37904e",
   "metadata": {},
   "source": [
    "#                                         Using a pretrained ViT Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e987276",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acddb61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  # For pre-trained models\n",
    "from PIL import Image  # For image loading\n",
    "import os  # For file path operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d116e7",
   "metadata": {},
   "source": [
    "Pdf folder images stored in Images Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: page_0_image_0.jpx\n",
      "Processing image: page_0_image_1.jpx\n",
      "Processing image: page_0_image_2.jpx\n",
      "Processing image: page_10_image_0.jpx\n",
      "Processing image: page_10_image_1.jpx\n",
      "Processing image: page_10_image_2.jpx\n",
      "Processing image: page_11_image_0.jpx\n",
      "Processing image: page_11_image_1.jpx\n",
      "Processing image: page_11_image_2.jpx\n",
      "Processing image: page_12_image_0.jpx\n",
      "Processing image: page_12_image_1.jpx\n",
      "Processing image: page_12_image_2.jpx\n",
      "Processing image: page_13_image_0.jpx\n",
      "Processing image: page_13_image_1.jpx\n",
      "Processing image: page_13_image_2.jpx\n",
      "Processing image: page_14_image_0.jpx\n",
      "Processing image: page_14_image_1.jpx\n",
      "Processing image: page_14_image_2.jpx\n",
      "Processing image: page_15_image_0.jpx\n",
      "Processing image: page_15_image_1.jpx\n",
      "Processing image: page_15_image_2.jpx\n",
      "Processing image: page_1_image_0.jpx\n",
      "Processing image: page_1_image_1.jpx\n",
      "Processing image: page_1_image_2.jpx\n",
      "Processing image: page_2_image_0.jpx\n",
      "Processing image: page_2_image_1.jpx\n",
      "Processing image: page_2_image_2.jpx\n",
      "Processing image: page_3_image_0.jpx\n",
      "Processing image: page_3_image_1.jpx\n",
      "Processing image: page_3_image_2.jpx\n",
      "Processing image: page_4_image_0.jpx\n",
      "Processing image: page_4_image_1.jpx\n",
      "Processing image: page_4_image_2.jpx\n",
      "Processing image: page_5_image_0.jpx\n",
      "Processing image: page_5_image_1.jpx\n",
      "Processing image: page_5_image_2.jpx\n",
      "Processing image: page_6_image_0.jpx\n",
      "Processing image: page_6_image_1.jpx\n",
      "Processing image: page_6_image_2.jpx\n",
      "Processing image: page_7_image_0.jpx\n",
      "Processing image: page_7_image_1.jpx\n",
      "Processing image: page_7_image_2.jpx\n",
      "Processing image: page_8_image_0.jpx\n",
      "Processing image: page_8_image_1.jpx\n",
      "Processing image: page_8_image_2.jpx\n",
      "Processing image: page_9_image_0.jpx\n",
      "Processing image: page_9_image_1.jpx\n",
      "Processing image: page_9_image_2.jpx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_images(image_folder):\n",
    "  \"\"\"\n",
    "  Processes images in a specified folder.\n",
    "\n",
    "  Args:\n",
    "    image_folder: Path to the folder containing images.\n",
    "  \"\"\"\n",
    "  for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpx\"):  # Check for .jpx extension\n",
    "      image_path = os.path.join(image_folder, filename)\n",
    "      # Process the image here (e.g., load using OpenCV or Pillow)\n",
    "      print(f\"Processing image: {filename}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"Images\"\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9dfb8",
   "metadata": {},
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d9333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: page_0_image_0.jpx\n",
      "Processed image: page_0_image_1.jpx\n",
      "Processed image: page_0_image_2.jpx\n",
      "Processed image: page_10_image_0.jpx\n",
      "Processed image: page_10_image_1.jpx\n",
      "Processed image: page_10_image_2.jpx\n",
      "Processed image: page_11_image_0.jpx\n",
      "Processed image: page_11_image_1.jpx\n",
      "Processed image: page_11_image_2.jpx\n",
      "Processed image: page_12_image_0.jpx\n",
      "Processed image: page_12_image_1.jpx\n",
      "Processed image: page_12_image_2.jpx\n",
      "Processed image: page_13_image_0.jpx\n",
      "Processed image: page_13_image_1.jpx\n",
      "Processed image: page_13_image_2.jpx\n",
      "Processed image: page_14_image_0.jpx\n",
      "Processed image: page_14_image_1.jpx\n",
      "Processed image: page_14_image_2.jpx\n",
      "Processed image: page_15_image_0.jpx\n",
      "Processed image: page_15_image_1.jpx\n",
      "Processed image: page_15_image_2.jpx\n",
      "Processed image: page_1_image_0.jpx\n",
      "Processed image: page_1_image_1.jpx\n",
      "Processed image: page_1_image_2.jpx\n",
      "Processed image: page_2_image_0.jpx\n",
      "Processed image: page_2_image_1.jpx\n",
      "Processed image: page_2_image_2.jpx\n",
      "Processed image: page_3_image_0.jpx\n",
      "Processed image: page_3_image_1.jpx\n",
      "Processed image: page_3_image_2.jpx\n",
      "Processed image: page_4_image_0.jpx\n",
      "Processed image: page_4_image_1.jpx\n",
      "Processed image: page_4_image_2.jpx\n",
      "Processed image: page_5_image_0.jpx\n",
      "Processed image: page_5_image_1.jpx\n",
      "Processed image: page_5_image_2.jpx\n",
      "Processed image: page_6_image_0.jpx\n",
      "Processed image: page_6_image_1.jpx\n",
      "Processed image: page_6_image_2.jpx\n",
      "Processed image: page_7_image_0.jpx\n",
      "Processed image: page_7_image_1.jpx\n",
      "Processed image: page_7_image_2.jpx\n",
      "Processed image: page_8_image_0.jpx\n",
      "Processed image: page_8_image_1.jpx\n",
      "Processed image: page_8_image_2.jpx\n",
      "Processed image: page_9_image_0.jpx\n",
      "Processed image: page_9_image_1.jpx\n",
      "Processed image: page_9_image_2.jpx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2  \n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "  \"\"\"\n",
    "  Loads, resizes, and normalizes an image for the transformer model.\n",
    "\n",
    "  Args:\n",
    "    image_path: Path to the image file.\n",
    "    target_size: Desired output size (e.g., 224x224 for some pre-trained models).\n",
    "\n",
    "  Returns:\n",
    "    A NumPy array representing the preprocessed image.\n",
    "  \"\"\"\n",
    "  image = cv2.imread(image_path)  # Load image using OpenCV\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary (model dependent)\n",
    "  image = cv2.resize(image, target_size)  # Resize to target size\n",
    "  image = image.astype('float32') / 255.0  # Normalize pixel values (0-1)\n",
    "  return image\n",
    "\n",
    "def process_images(image_folder):\n",
    "  \"\"\"\n",
    "  Processes images in a specified folder, loading and preprocessing them.\n",
    "\n",
    "  Args:\n",
    "    image_folder: Path to the folder containing images.\n",
    "  \"\"\"\n",
    "  preprocessed_images = []  # List to store preprocessed images\n",
    "  for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpx\"):  # Check for .jpx extension\n",
    "      image_path = os.path.join(image_folder, filename)\n",
    "      preprocessed_image = preprocess_image(image_path)\n",
    "      preprocessed_images.append(preprocessed_image)\n",
    "      print(f\"Processed image: {filename}\")\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"Images\"\n",
    "process_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63c49a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "  \"\"\"\n",
    "  Loads an image from a file, resizes, and normalizes for ViT.\n",
    "\n",
    "  Args:\n",
    "      image_path: Path to the image file.\n",
    "      target_size: Target size for resizing (default: (224, 224)).\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array representing the preprocessed image.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load the image using PIL\n",
    "  img = Image.open(image_path)\n",
    "\n",
    "  # Resize the image to the target size\n",
    "  img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "  # Convert the image to a NumPy array and normalize to range [0, 1]\n",
    "  image_data = np.array(img) / 255.0  # Normalize pixel values\n",
    "\n",
    "  # Assuming the ViT model expects channels first (B, G, R) format\n",
    "  image_data = np.expand_dims(image_data, axis=0)  # Add a channel dimension if needed\n",
    "\n",
    "  image_tensor = tf.convert_to_tensor(image_data)\n",
    "  return image_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a1af3",
   "metadata": {},
   "source": [
    "# Importing a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3741d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f625240e909a4ad1b55da0dfcc37f04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0eba7454924b52a5111f76d9782813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# image_folder = \"Images\"\n",
    "encoded_features = []  # List to store encoded features\n",
    "\n",
    "# Loop through image files in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "  if filename.endswith(\".jpx\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check for common image extensions\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "    # Load and preprocess the image \n",
    "    image_data = load_and_preprocess_image(image_path)  # Function to load and preprocess the image\n",
    "\n",
    "    # Passing the preprocessed image data through the ViT model\n",
    "    encoded_feature = vit_model(image_data)\n",
    "    encoded_features.append(encoded_feature)\n",
    "\n",
    "# Now we have a list of encoded features for each image in the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40fda142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # Assuming PIL for image loading\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "  \"\"\"\n",
    "  Loads an image from a file, resizes, and normalizes for ViT.\n",
    "\n",
    "  Args:\n",
    "      image_path: Path to the image file.\n",
    "      target_size: Target size for resizing (default: (224, 224)).\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array representing the preprocessed image.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load the image using PIL\n",
    "  img = Image.open(image_path)\n",
    "\n",
    "  # Resize the image to the target size\n",
    "  img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "  # Convert the image to a NumPy array and normalize to range [0, 1]\n",
    "  image_data = np.array(img) / 255.0  # Normalize pixel values\n",
    "\n",
    "  # Assuming the ViT model expects channels first (B, G, R) format\n",
    "  image_data = np.expand_dims(image_data, axis=0)  \n",
    "\n",
    "  return image_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ce0e6",
   "metadata": {},
   "source": [
    "# Saving Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  # Assuming you want to save in HDF5 format\n",
    "\n",
    "with h5py.File('encoded_features.h5', 'w') as hf:\n",
    "  hf.create_dataset('features', data=encoded_features)\n",
    "\n",
    "# This will create a file 'encoded_features.h5' containing the features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
